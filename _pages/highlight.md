---
layout: archive
title: "Highlight"
permalink: /highlight/
author_profile: true
---
### Research highlights

<div class="highlight-grid">
  <div class="highlight-card">
    <div class="highlight-bullet"><span class="highlight-dot">&bull;</span> <strong>GraspGPT (IEEE RA-L 2023)</strong> — Task-oriented grasping with LLM semantic knowledge.</div>
    <div class="responsive-video">
      <iframe src="https://www.youtube-nocookie.com/embed/qq0DMdHRw1E" title="GraspGPT video" loading="lazy" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
    </div>
    <div class="highlight-links"><a href="https://arxiv.org/pdf/2307.13204">Paper</a></div>
  </div>

  <div class="highlight-card">
    <div class="highlight-bullet"><span class="highlight-dot">&bull;</span> <strong>FoundationGrasp (IEEE T-ASE 2025)</strong> — Generalizable task-oriented grasping with foundation models.</div>
    <div class="responsive-video">
      <iframe src="https://www.youtube-nocookie.com/embed/B6iTa6BRB1w" title="FoundationGrasp video" loading="lazy" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
    </div>
    <div class="highlight-links"><a href="https://arxiv.org/pdf/2404.10399">Paper</a></div>
  </div>

  <div class="highlight-card">
    <div class="highlight-bullet"><span class="highlight-dot">&bull;</span> <strong>HGDiffuser (IROS 2025)</strong> — Efficient task-oriented grasp generation via human-guided grasp diffusion models.</div>
    <div class="responsive-video">
      <iframe src="https://www.youtube-nocookie.com/embed/fUt6cE9SZoY" title="HGDiffuser video" loading="lazy" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
    </div>
    <div class="highlight-links"><a href="https://arxiv.org/pdf/2503.00508">Paper</a> · <a href="https://github.com/red0orange/handgrasp_ws">Code</a></div>
  </div>

  <div class="highlight-card">
    <div class="highlight-bullet"><span class="highlight-dot">&bull;</span> <strong>Multi-view Rearrangement (ICRA 2024)</strong> — Efficient object rearrangement via multi-view fusion.</div>
    <div class="responsive-video">
      <iframe src="https://www.youtube-nocookie.com/embed/oUlDwmMbjQU" title="Multi-view rearrangement video" loading="lazy" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
    </div>
    <div class="highlight-links"><a href="https://arxiv.org/pdf/2309.08994">Paper</a></div>
  </div>
</div>

<div class="highlight-note">
  <span class="highlight-dot">&bull;</span> <strong>CloudEdgeSLAM (IEEE TVT 2023)</strong> — Cloud learning meets edge model-based SLAM. <a href="https://ieeexplore.ieee.org/abstract/document/10264105">Paper</a>
</div>

### Competitions

- **RoboMaster Robotics Competition** (Algorithm Group Leader): National Second Prize (2020)
- **National College Students' Smart Car Competition** (Team Leader): National Third Prize (2020)
- **American Interdisciplinary Contest in Modeling (ICM/MCM)**: Meritorious Winner (top 7.09%) (2021)

### Awards and honors

- **The 1st Academic Research Star of Zhongguancun Academy** (2026)
- **SCNU First-Class Scholarship** (2020)

