---
layout: archive
title: "Publications"
permalink: /publications/
author_profile: true
---

<h3>Publications</h3>

<ul>
  <li>
    <strong>Huang, Dehao</strong>, Wenlong Dong, Chao Tang, Hong Zhang.
    <em>HGDiffuser: Efficient Task-Oriented Grasp Generation via Human-Guided Grasp Diffusion Models.</em>
    <strong>IROS 2025</strong> (accepted).
    <br/>
    <a href="https://arxiv.org/pdf/2503.00508">Paper</a> ·
    <a href="https://sites.google.com/view/hgdiffuser">Video</a> ·
    <a href="https://github.com/red0orange/handgrasp_ws">Code</a>
  </li>
  <li>
    <strong>Huang, Dehao</strong>, Chao Tang, Hong Zhang.
    <em>Efficient Object Rearrangement via Multi-view Fusion.</em>
    <strong>ICRA 2024</strong> (accepted).
    <br/>
    <a href="https://arxiv.org/pdf/2309.08994">Paper</a> ·
    <a href="https://sites.google.com/view/multi-view-rearr">Video</a>
  </li>
  <li>
    Shao, Chenyang, <strong>Huang, Dehao</strong>, Yu Li, Keyu Zhao, Weiquan Lin, Yining Zhang, Qingbin Zeng, et al.
    <em>OmniScientist: Toward a Co-evolving Ecosystem of Human and AI Scientists.</em>
    <strong>arXiv 2025</strong>.
    <br/>
    <a href="https://arxiv.org/pdf/2511.16931">Paper</a>
  </li>
  <li>
    Tang, Chao, <strong>Huang, Dehao</strong>, Wenlong Dong, Ruinian Xu, Hong Zhang.
    <em>FoundationGrasp: Generalizable Task-Oriented Grasping with Foundation Models.</em>
    <strong>IEEE T-ASE 2025</strong> (accepted).
    <br/>
    <a href="https://arxiv.org/pdf/2404.10399">Paper</a> ·
    <a href="https://sites.google.com/view/foundationgrasp/">Video</a>
  </li>
  <li>
    Tang, Chao, <strong>Huang, Dehao</strong>, Wenqi Ge, Weiyu Liu, Hong Zhang.
    <em>GraspGPT: Leveraging Semantic Knowledge from a Large Language Model for Task-Oriented Grasping.</em>
    <strong>IEEE RA-L 2023</strong> (accepted).
    <br/>
    <a href="https://arxiv.org/pdf/2307.13204">Paper</a> ·
    <a href="https://sites.google.com/view/graspgpt/">Video</a>
  </li>
  <li>
    Tang, Chao, <strong>Huang, Dehao</strong>, Lingxiao Meng, Weiyu Liu, Hong Zhang.
    <em>Task-Oriented Grasp Prediction with Visual-Language Inputs.</em>
    <strong>IROS 2023</strong> (accepted).
    <br/>
    <a href="https://arxiv.org/pdf/2302.14355">Paper</a> ·
    <a href="https://www.youtube.com/watch?v=e1wfYQPeAXU">Video</a>
  </li>
  <li>
    Chen, Weinan, <strong>Huang, Dehao</strong>, Yaling Pan, Guangcheng Chen, Jiahao Ruan, Jingwen Yu, Jiamin Zheng, Hong Zhang.
    <em>Cloud Learning-based Meets Edge Model-based: Robots Don't Need to Build All the Submaps Itself.</em>
    <strong>IEEE TVT 2023</strong> (accepted).
    <br/>
    <a href="https://ieeexplore.ieee.org/abstract/document/10264105">Paper</a>
  </li>
  <li>
    <strong>Huang, Dehao</strong>, Jintao Cheng, Rui Fan, Zhihao Su, Qiongxiong Ma, Jie Li.
    <em>Bone marrow cell recognition: Training deep object detection with a new loss function.</em>
    <strong>IST 2021</strong> (accepted).
    <br/>
    <a href="https://arxiv.org/pdf/2110.12647">Paper</a>
  </li>
  <li>
    Guo, Liang, Peiduo Huang, <strong>Huang, Dehao</strong>, Zilan Li, Chenglong She, Qianhang Guo, Qingmao Zhang, Jiaming Li, Qiongxiong Ma, Jie Li.
    <em>A classification method to classify bone marrow cells with class imbalance problem.</em>
    <strong>BSPC 2022</strong> (accepted).
    <br/>
    <a href="https://www.sciencedirect.com/science/article/abs/pii/S1746809421008934">Paper</a>
  </li>
</ul>
